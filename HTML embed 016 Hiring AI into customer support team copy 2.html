<!DOCTYPE html>
<html>
<head>
<title>Hiring AI into customer support team</title>
</head>
<body>

<p>Access the article here: [https://app.happeo.com/channels/106430467/CustomerExperienceSuccess/article/77969421]</p>

<p>Hiring AI into customer support team /Part 1 of 2/ Why ChatGPT is the tip of the iceberg. The key difference between a typical chatbot and an AI-powered chatbot. What makes AI so hot for customer support right now. 7 use cases that will (wrongly) make support agents feel redundant. What is GPT and Large Language Models? By now, a lot of us are familiar with ChatGPT. That's an interface or a way to access the large language model that is GPT.</p>

<p>GPT (or Generative Pre-trained Transformer) is a foundation model that provides us with &ldquo;general purpose&rdquo; features which can be adapted to multiple use cases.</p>

<p>Think of a foundation model as the base, or a starting point for creating specialized AI applications. Being a large language model, GPT is trained on a massive amount of text data from sources like books, articles, and websites. By learning from all this information, the foundation model gains a general understanding of language, grammar, and a wide range of other topics.</p>

<p>Once the foundation model has been created, we can then fine-tune it to be more specialized for specific tasks, such as answering questions about a particular subject or translating text between languages.</p>

<p>The idea is to have a solid foundation on which various AI applications can be built, making it easier and more efficient to create AI tools that can help people in their everyday lives.</p>

<p>This has made machine learning and AI more accessible than ever, and machine learning models will become more and more available seeing how successful GPT is as a foundation model.</p>

<p>How is GPT different from the current chatbots? Some time ago, the best implementation of any chatbots had some sort of natural language processing capabilities or a rule-based text processing.</p>

<p>GPT chatbots and traditional natural language processing/rule-based chatbots both aim to facilitate human-like conversations. However, they differ in their underlying technology and capabilities, with GPT chatbots offering significant advantages.</p>

<p>Chatbots that are running GPT are aware of vast amounts of text data, enabling them to grasp complex language patterns, idiomatic expressions, and diverse topics. In contrast, rule-based chatbots rely on predefined rules and keywords, often struggling with nuances in language and context.</p>

<p>They are better at understanding context and maintaining coherence throughout a conversation. Rule-based chatbots, which follow a predefined decision tree, often struggle to maintain context, leading to disjointed and less natural conversations.</p>

<p>GPT chatbots leverage pre-trained models, reducing the time and resources needed for development. Rule-based and natural language processing chatbots demand extensive maintenance on rules and the user inputs, which can be time-consuming and expensive.</p>

<p>Customer support + AI = &hearts;&#65039; AI empowers companies to dramatically increase speed and quality of the customer support services. The effect is that the companies that don't use this technology will gradually lag behind the competitors.</p>

<p>Initially, it will be most evident from the speed with which competitors answer customers' questions. Then the customers will start to notice the higher quality of responses. Then they will realize how much more successful they could be with your competitor. Then some of the customers will leave you.</p>

<p>The companies need to realize that the buzz around &ldquo;ChatGPT&rdquo; is hyping just the interface and the tip of the iceberg, while many more use cases are equally or even more powerful for your business.</p>

<p>Ideal use cases in customer support It's an information technology, so it heavily depends on content about your product, your terminology, context of your support cases, etc. What makes these solutions so powerful is that they can assist throughout the whole cycle:</p>

<p>Use the AI-powered support system to summarize the essence of the customer support case. What is the customer saying? What will help him/her? Based on use case #1, you can check if the solution to the customer's problem is already described. Better yet, ask the AI solution to provide a solution, and it will tell you if it doesn't exist yet and should be written! Now ask the AI solution to write the solution. You - as a support agent - receive a question from the customer. Ask the AI tool to look up the right solution. Or better yet, ask the AI tool to suggest what you should respond to the customer (during a Live chat with the customer - visible in the top left part of the image) Assess the customer sentiment after the chat The solution didn't help? Offer the customer the opportunity to book an appointment with a consultant. Now, back to the beginning of the cycle - summarize customer feedback and sentiment. What is the overall experience of this customer? What else might the customer need? Will AI make support roles redundant? No. Focus on what only people can do: real human communication with customers, inventing new products and services, tweaking AI technology to deliver ever more value to customers and support teams internally, stepping in when situations arise that no system can solve (or when the system is down?!).</p>

<p>Actual experiments in Visma and their preliminary results. Avoid these 4 pitfalls. What specifically can you do to start implementing this technology? Choosing the platforms. Who can help me take the first/next step? A couple of experiments in Visma customer support with preliminary results</p>

<p>Pitfalls to avoid This great article by Jacob Nyman (AI Director, Visma Resolve) outlines the overall risks and recommended precautions related to AI tools and Large Language Models (LLMs) very well: [https://space.visma.com/channels/103055360/GlobalMessageBoard/article/77950975]</p>

<p>Here are some pitfalls and concerns related specifically to AI in customer support:</p>

<p>Start with the use cases, not the technology What are the needs of your customers that require the most effort and/or time of your organization? Which do you consider low-added-value or repeating tasks, candidates for automation? Before adding any technology on top of the existing process, consider optimizing the workflow (what can you STOP doing?). Identify the use cases in the optimized process for the AI to do.</p>

<p>Understand model limitations, e.g. language Visma has companies all over the world that might be interested in this technology. Even though the GPT model works relatively well with most languages, its performance is generally better in English. This is because the majority of the training data for GPT comes from English-language sources, such as websites, books, and articles. It would require some experimenting to adjust it to the needs of Visma companies. This is especially relevant for customer-facing AI solutions. Therefore, be mindful of this aspect and experiment small before major investments.</p>

<p>GDPR and data storage If you utilize Azure OpenAI through Visma&rsquo;s corporate agreement with Microsoft (this means that the Azure subscription was created by Visma), you can ensure processing within the EU, opt out of model training, and also opt out of human inspection in certain cases. This is currently supported for GPT-3 and GPT-3.5 for direct use and fine-tuning. If you choose to use OpenAI APIs for your implementations, consider that starting from March 1, 2023, OpenAI will not use data submitted by customers via their API to train or improve their models, unless you explicitly decide to share your data with them for this purpose. You can opt-in to share data. Any data sent through the API will be retained for abuse and misuse monitoring purposes for a maximum of 30 days, after which it will be deleted (unless otherwise required by law). With standard OpenAI APIs (without Azure), all customer data is processed and stored in the US. They do not currently store data in Europe or in other countries.</p>

<p>Be brave with experiments Be cautious, start small. Consider starting experimenting with your most relevant use cases in one small area. Next, launch a minimum viable solution that you can field-test internally. As done by the Visma companies that already experiment with it, consider using it first to empower your internal teams. Practice makes perfect. Once you're confident the solution will help customers, launch it for customer-facing. Then gather feedback and improve.</p>

<p>How to get started?</p>

<p>Define your most relevant use cases and describe what business results you expect an AI solution will provide (i.e., a brief business case). If you already know the platform, consider the cost drivers, such as the cost of any additional interfaces, CRM platform features, as well as the AI models (e.g., OpenAI describes their models and pricing online). If you are in doubt about which platform or model to choose, please write in the Slack channel #sig-ai-customer-support Review the current business process of the specific use case(s) and, if needed, optimize it before adding AI on top of it (see the section &ldquo;Pitfalls to avoid&rdquo; above).</p>

<p>Depending on the use case, check the related risks, such as GDPR, data storage location, etc. (again, section &ldquo;Pitfalls to avoid&rdquo;).</p>

<p>Check if you need to prepare any content or platforms that the AI solution will need for your use case. For example, a suitable chat application, CRM system, knowledge articles, appointment scheduler, etc.</p>

<p>Consider the most suitable platform among all the available ones. Keep this selection criteria in mind:</p>

<p>Do you have a CRM that supports AI capabilities? Then look at that first before switching to another platform (usually an extensive project). Do you want to use an out-of-the-box platform? This may be more suitable if you have limited technical knowledge and a fairly standard use case. (see below options) Do you have a specific use case or out-of-the-box doesn't cover your needs? Then you can look at the potential for a custom solution. This is possible for any application or platform with the capability to integrate over an API. Platforms and companies that use Artificial Intelligence for support in Visma: [https://docs.google.com/presentation/d/1zt004YKj5IiS6t4vOjeaM5n6RSy8hrLDrX6wg83y4Ws/edit?usp=sharing]</p>

<p>After you have chosen the platform you want to experiment with, here's what you can do.</p>

<p>If you are interested in the Salesforce Einstein GPT - Pilot is announced but not accessible yet, a Visma internal demo is expected in May'23, together with more information about availability. If you are interested in this platform, contact marika.ernstreite@visma.com If you are working with a support ticketing system (Salesforce Service Cloud, Zendesk, Hubspot, or others) that doesn&rsquo;t currently support out-of-the-box GPT integration and you are looking for a custom solution, reach out to edgars.skore@visma.com to discuss technical implementations. If you are interested in any of the other platforms, please follow the instructions of those specific platforms, keeping in mind the precautions mentioned in the section &quot;Pitfalls to avoid&quot; above.</p>

<p>Who can help?</p>

<p>Please write your question in the Slack channel #sig-ai-customer-support, and we will get back to you as soon as possible.</p>

</body>
</html>